{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load episode data from previous scraping exercise\n",
    "with open('simpsons_scripts.pickle', 'rb') as eps_file:\n",
    "    episodes = pickle.load(eps_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the seasons and add scripts to a list to facilitate vectorization\n",
    "ep_scripts = []\n",
    "ep_script_lookup = {}\n",
    "for season in episodes:\n",
    "    for episode in episodes[season]:\n",
    "        ep_scripts.append(episodes[season][episode]['script'])\n",
    "        ep_script_lookup[len(ep_scripts)-1] = {}\n",
    "        ep_script_lookup[len(ep_scripts)-1]['season_num'] = season\n",
    "        ep_script_lookup[len(ep_scripts)-1]['ep_num'] = episode\n",
    "        ep_script_lookup[len(ep_scripts)-1]['ep_title'] = episodes[season][episode]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Scikit-Learn TF-IDF feature\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TODO: experiment with parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', lowercase=True, ngram_range=(1,3), min_df=2, max_df=0.5)\n",
    "X = tfidf_vectorizer.fit_transform(ep_scripts)\n",
    "X_array = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pick out top words for each episode\n",
    "features = tfidf_vectorizer.get_feature_names()\n",
    "current_ep_idx = 0\n",
    "for season_num in episodes:\n",
    "    for ep_num in episodes[season_num]:\n",
    "        current_ep = np.array(X_array[current_ep_idx])\n",
    "        current_ep_words = np.nonzero(current_ep)[0]  # Take only first dimension since there's only one\n",
    "        words_dict = [{'index':idx, 'phrase': features[idx], 'score': current_ep[idx]} for idx in current_ep_words]\n",
    "        max_num_words = min(1000, len(words_dict))\n",
    "        top_words = sorted(words_dict, key=lambda x: x['score'], reverse=True)[:max_num_words]\n",
    "        episodes[season_num][ep_num]['top_words'] = top_words\n",
    "        current_ep_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file with top 1000 words for later analysis\n",
    "\n",
    "with open('simpsons_scripts_tfidf.pickle', 'wb') as eps_file_tfidf:\n",
    "    pickle.dump(episodes, eps_file_tfidf, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write episode summaries with top 5 phrases to file\n",
    "\n",
    "with open('simpsons_scripts_summaries.txt', 'w') as eps_summaries:\n",
    "    for season_num in episodes:\n",
    "        eps_summaries.write('Season {season_num}\\n'.format(season_num=season_num))\n",
    "        for ep_num in episodes[season_num]:\n",
    "            eps_summaries.write('\\tTitle: {title}\\n'.format(title=episodes[season_num][ep_num]['title']))\n",
    "            eps_summaries.write('\\tSummary: {summary}\\n'.format(summary=episodes[season_num][ep_num]['summary']))\n",
    "\n",
    "            top_5_words_info = episodes[season_num][ep_num]['top_words'][:5]\n",
    "            top_5_words = [x['phrase'] for x in top_5_words_info]\n",
    "\n",
    "            eps_summaries.write('\\tTop Words: {top_words}\\n\\n'.format(top_words=top_5_words))\n",
    "            \n",
    "        eps_summaries.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
