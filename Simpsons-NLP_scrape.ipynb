{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements for cells\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_season_num(season_text):\n",
    "    season_num = -1\n",
    "    if season_text and len(season_text) > 0:\n",
    "        last_space = season_text.rfind(' ')\n",
    "        if last_space > -1:\n",
    "            season_num_text = season_text[last_space+1:]\n",
    "            if season_num_text.isnumeric():\n",
    "                season_num = int(season_num_text)\n",
    "    \n",
    "    return season_num\n",
    "\n",
    "def extract_ep_info(ep_text):\n",
    "    ep_num = -1\n",
    "    ep_title = None\n",
    "    if ep_text and len(ep_text) > 0:\n",
    "        first_dot = ep_text.find('.')\n",
    "        if first_dot > -1 and first_dot < len(ep_text)-1:\n",
    "            ep_num_text = ep_text[:first_dot]\n",
    "            if ep_num_text.strip().isnumeric():\n",
    "                ep_num = int(ep_num_text)\n",
    "                ep_title = ep_text[first_dot+1:].strip()\n",
    "    \n",
    "    return ep_num, ep_title\n",
    "\n",
    "def clean_script(text):\n",
    "    \"\"\"Replace any white space with a single space, and fix up backslashes.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.replace(\"\\'\", \"'\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the methods above\n",
    "\n",
    "assert(extract_season_num('Season 1') == 1)\n",
    "assert(extract_season_num('Season 23') == 23)\n",
    "assert(extract_season_num('Season43') == -1)\n",
    "assert(extract_season_num('asdfasdas werqwq') == -1)\n",
    "\n",
    "assert(extract_ep_info('1. Some episode') == (1, 'Some episode'))\n",
    "assert(extract_ep_info('2.NoSpaceForSomeReason') == (2, 'NoSpaceForSomeReason'))\n",
    "assert(extract_ep_info('Someone. messed up!') == (-1, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Season 1...\n",
      "Downloading Season 2...\n",
      "Downloading Season 3...\n",
      "Downloading Season 4...\n",
      "Downloading Season 5...\n",
      "Downloading Season 6...\n",
      "Downloading Season 7...\n",
      "Downloading Season 8...\n",
      "Downloading Season 9...\n",
      "Downloading Season 10...\n",
      "Downloading Season 11...\n",
      "Downloading Season 12...\n",
      "Downloading Season 13...\n",
      "Downloading Season 14...\n",
      "Downloading Season 15...\n",
      "Downloading Season 16...\n",
      "Downloading Season 17...\n",
      "Downloading Season 18...\n",
      "Downloading Season 19...\n",
      "Downloading Season 20...\n",
      "Downloading Season 21...\n",
      "Downloading Season 22...\n",
      "Downloading Season 23...\n",
      "Downloading Season 24...\n",
      "Downloading Season 25...\n",
      "Downloading Season 26...\n",
      "Downloading Season 27...\n",
      "Downloading Season 28...\n",
      "Downloading Season 29...\n",
      "Downloading Season 30...\n",
      "Time: 665.754105091095\n"
     ]
    }
   ],
   "source": [
    "# Import the raw scripts from \"Springfield, Springfield!\" site\n",
    "script_dl_start = time()\n",
    "\n",
    "script_base_url = 'https://www.springfieldspringfield.co.uk'\n",
    "episodes = {}\n",
    "\n",
    "# Load up the main episodes page\n",
    "eps_pg = urlopen(script_base_url + '/episode_scripts.php?tv-show=the-simpsons')\n",
    "eps_pg_soup = BeautifulSoup(eps_pg, 'html.parser')\n",
    "\n",
    "season_divs = eps_pg_soup.select('div.season-episodes')\n",
    "# Loop through every season and get the links to the episodes\n",
    "for season_div in season_divs:\n",
    "    season_name = season_div.find('h3').get_text()\n",
    "    season_num = extract_season_num(season_name)\n",
    "    episodes[season_num] = {}\n",
    "    ep_links = season_div.select('a.season-episode-title')\n",
    "    print('Downloading Season {season_num}...'.format(season_num=season_num))\n",
    "    \n",
    "    # Loop through all the episodes per season and save the script text\n",
    "    for ep_link in ep_links:\n",
    "        ep_info = ep_link.get_text()\n",
    "        ep_num, ep_title = extract_ep_info(ep_info)\n",
    "        episodes[season_num][ep_num] = {}\n",
    "        script_link = ep_link['href']\n",
    "        script_pg = urlopen(script_base_url + '/' + script_link)\n",
    "        script_pg_soup = BeautifulSoup(script_pg)\n",
    "        script_text_raw = script_pg_soup.select('div.scrolling-script-container')[0].get_text()\n",
    "        script_text_clean = clean_script(script_text_raw)\n",
    "        episodes[season_num][ep_num]['script'] = script_text_clean\n",
    "        episodes[season_num][ep_num]['title'] = ep_title\n",
    "        \n",
    "elapsed_time = time() - script_dl_start\n",
    "print('Time: ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading summaries for Season 1...\n",
      "Downloading summaries for Season 2...\n",
      "Downloading summaries for Season 3...\n",
      "Downloading summaries for Season 4...\n",
      "Downloading summaries for Season 5...\n",
      "Downloading summaries for Season 6...\n",
      "Downloading summaries for Season 7...\n",
      "Downloading summaries for Season 8...\n",
      "Downloading summaries for Season 9...\n",
      "Downloading summaries for Season 10...\n",
      "Downloading summaries for Season 11...\n",
      "Downloading summaries for Season 12...\n",
      "Downloading summaries for Season 13...\n",
      "Downloading summaries for Season 14...\n",
      "Downloading summaries for Season 15...\n",
      "Downloading summaries for Season 16...\n",
      "Downloading summaries for Season 17...\n",
      "Downloading summaries for Season 18...\n",
      "Downloading summaries for Season 19...\n",
      "Downloading summaries for Season 20...\n",
      "Downloading summaries for Season 21...\n",
      "Downloading summaries for Season 22...\n",
      "Downloading summaries for Season 23...\n",
      "Downloading summaries for Season 24...\n",
      "Downloading summaries for Season 25...\n",
      "Downloading summaries for Season 26...\n",
      "Downloading summaries for Season 27...\n",
      "Downloading summaries for Season 28...\n",
      "Downloading summaries for Season 29...\n",
      "Downloading summaries for Season 30...\n",
      "Time: 917.4979720115662\n"
     ]
    }
   ],
   "source": [
    "# Import episode summaries from pogdesign TV Calendar\n",
    "summary_dl_task_start = time()\n",
    "ep_summary_url_format = 'https://www.pogdesign.co.uk/cat/The-Simpsons/Season-{season_num}/Episode-{ep_num}'\n",
    "\n",
    "for season_num in episodes:\n",
    "    print('Downloading summaries for Season {season_num}...'.format(season_num=season_num))\n",
    "    for ep_num in episodes[season_num]:\n",
    "        try:\n",
    "            summary_pg = urlopen(ep_summary_url_format.format(season_num=season_num, ep_num=ep_num))\n",
    "            summary_pg_soup = BeautifulSoup(summary_pg, 'html.parser')\n",
    "            ep_summary = summary_pg_soup.find('p', class_='sumtext').get_text()\n",
    "            episodes[season_num][ep_num]['summary'] = clean_script(ep_summary)\n",
    "        except Exception as e:\n",
    "            print('\\tError at Season {season_num} episode {ep_num}: {error}'.format(season_num=season_num, ep_num=ep_num, error=str(e)))\n",
    "            continue\n",
    "\n",
    "elapsed_time = time() - summary_dl_task_start\n",
    "print('Time: {elapsed_time}'.format(elapsed_time=str(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the episode data for use later\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('simpsons_scripts.pickle', 'wb') as eps_file:\n",
    "    pickle.dump(episodes, eps_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
